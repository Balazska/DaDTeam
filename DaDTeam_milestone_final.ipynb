{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DaDTeam_milestone_base_new_BI_ATT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCcXAM7RZlXz"
      },
      "source": [
        "# Milestone III.\n",
        "\n",
        "Basic training and evaluation process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oru06QvpZlXz"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "#import seaborn as sns\n",
        "import numpy as np\n",
        "import json\n",
        "import pprint"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "yctb0xfDt-os",
        "outputId": "029c9053-6fce-4bd8-9a25-1641a95c738c"
      },
      "source": [
        "\"\"\"\n",
        "GLOVE DOWNLOAD (IF NECESSARY)\n",
        "\"\"\"\n",
        "# download glove (IT IS NOT NECESSARY IN THE DOCKER CONTAINER, GLOVE IS ALREADY DOWNLOADED THERE)\n",
        "#!wget \"http://nlp.stanford.edu/data/glove.6B.zip\" -O temp.zip\n",
        "#!unzip temp.zip -d glove\n",
        "#!rm temp.zip\n",
        "#root_path = ''\n",
        "\n",
        "\"\"\"\n",
        "ATTACH GLOVE FROM GOOGLE DRIVE (IF YOU HAVE IT)\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "root_path = 'drive/My Drive/Uni/msc_sem4/deeplearning'  #change dir to your project folder\n",
        "#root_path = 'drive/My Drive/msc/dl_hf/' \n",
        "\n",
        "\"\"\"\n",
        "IF GLOVE IS STORED IN THE GLOVE FOLDER\n",
        "\"\"\"\n",
        "# root_path = ''"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nIF GLOVE IS STORED IN THE GLOVE FOLDER\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG1rOu7tvha8",
        "outputId": "b04fc0da-2941-450b-9475-935ecdf26846"
      },
      "source": [
        "\"\"\"\n",
        "DOWNLOAD DATA\n",
        "\"\"\"\n",
        "!mkdir data\n",
        "!wget -c https://smresearchstorage.blob.core.windows.net/smcalflow-public/smcalflow.full.data.tgz -O - | tar -xz -C data"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "--2020-12-08 19:00:23--  https://smresearchstorage.blob.core.windows.net/smcalflow-public/smcalflow.full.data.tgz\n",
            "Resolving smresearchstorage.blob.core.windows.net (smresearchstorage.blob.core.windows.net)... 52.191.176.36\n",
            "Connecting to smresearchstorage.blob.core.windows.net (smresearchstorage.blob.core.windows.net)|52.191.176.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13703288 (13M) [application/x-gzip]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]  13.07M  7.18MB/s    in 1.8s    \n",
            "\n",
            "2020-12-08 19:00:25 (7.18 MB/s) - written to stdout [13703288/13703288]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpqt1ioGsun8"
      },
      "source": [
        "#NOTEBOOK CONTROL VARIABLES\n",
        "\n",
        "# DO NOT MODIFY\n",
        "# Model types\n",
        "MODEL_BILSTM = \"bilstm\"\n",
        "MODEL_LSTM = \"lstm\"\n",
        "\n",
        "# Run mode\n",
        "RUN_TESTMODE = \"test\" # train in 20000 data\n",
        "RUN_FULLMODE = \"full\"\n",
        "# END DO NOT MODIFY\n",
        "\n",
        "# NOTEBOOK SETTINGS\n",
        "MODEL_TYPE=MODEL_LSTM\n",
        "RUN_MODE=RUN_FULLMODE\n",
        "\n",
        "# Attention layer, set true to include attention layer\n",
        "ATTENTION_LAYER = False\n",
        "\n",
        "HIDDEN_DIM = 8 # for lstm and bilstm mode\n",
        "# Model fit parameters\n",
        "BATCH_SIZE=32\n",
        "EPOCHS=3\n",
        "# Persist model\n",
        "PERSIST_MODEL_AS = None # add a filename if you want to save the model at the end\n",
        "# set False if the data needs to be downloaded\n",
        "DATA_EXISTS=True\n",
        "\n",
        "PARAMETER_REPLACEMENT=False"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-8wbfGRZlXz"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub0mcf7cv04h"
      },
      "source": [
        "import json"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-8UTcSgZlXz"
      },
      "source": [
        "# load train dataset\n",
        "train = []\n",
        "with open(\"data/train.dataflow_dialogues.jsonl\") as trainfile:\n",
        "    content = trainfile.read()\n",
        "    train = [json.loads(line) for line in content.splitlines()]\n",
        "\n",
        "# load validation data\n",
        "valid = []\n",
        "with open(\"data/valid.dataflow_dialogues.jsonl\") as validfile:\n",
        "    content = validfile.read()\n",
        "    valid = [json.loads(line) for line in content.splitlines()]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A62dISrcZlX0"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0lh1GxBZlX0"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# tokenized_lispress is an external function copied from \n",
        "# https://github.com/microsoft/task_oriented_dialogue_as_dataflow_synthesis\n",
        "# Lispress is the program code to evaluate the answer to a user utturance\n",
        "# The function tokenizes the lispress input string\n",
        "from lispress_tokenizer import tokenized_lispress"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8f_kCTxZlX0"
      },
      "source": [
        "# BOS and EOS indicate the beginning and ending of sentences\n",
        "def tokenizeLispressWithEndings(dataset):\n",
        "    '''\n",
        "    Tokenizes lispress of each turn in the given dataset.\n",
        "    The <bos> and <eos> tokens are appended to the token list.\n",
        "\n",
        "    Returns nothing since it modifies the dataset\n",
        "    '''\n",
        "    for dialog in dataset:\n",
        "        for turn in dialog[\"turns\"]:\n",
        "            turn['lispress_tokenized'] = ['<bos>'] + tokenized_lispress(turn['lispress']) + ['<eos>']"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yekkT2T4t9ai"
      },
      "source": [
        "# separate Xpm Xam type string is user utterances"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mcI86kHZlX0",
        "outputId": "0b4be63c-bb57-4e23-8e47-ca2c7e2901c1"
      },
      "source": [
        "# create a tokenizer and fit on the sentences of the train data dialogues\n",
        "tokenizer_user = Tokenizer()\n",
        "dialogue_sent = [turn['user_utterance']['original_text'] for dialog in train for turn in dialog['turns'] ]\n",
        "tokenizer_user.fit_on_texts(dialogue_sent)\n",
        "# index of \"the\"\n",
        "tokenizer_user.word_index[\"the\"]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZNOOIC7ZlX0"
      },
      "source": [
        "# create a tokenizer and fit on the tokenized lispress answers of the train data dialogues\n",
        "lispress_tokenizer = Tokenizer()\n",
        "\n",
        "# Tokenize lispress in train and valid according to a predefined logic\n",
        "tokenizeLispressWithEndings(train)\n",
        "tokenizeLispressWithEndings(valid)\n",
        "\n",
        "# Tokenizer.fit_on_texts method can take list of list of strings as argument assuming the strings are tokens\n",
        "dialogue_sent_lispress = [turn['lispress_tokenized'] for dialog in train for turn in dialog['turns']]\n",
        "lispress_tokenizer.fit_on_texts(dialogue_sent_lispress)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpMnMKgcZlX0",
        "outputId": "0e05012c-b984-4daf-8680-6c65e0eaf3a5"
      },
      "source": [
        "# Example tokenized lispres\n",
        "print(dialogue_sent_lispress[1])\n",
        "print(lispress_tokenizer.word_counts['('])\n",
        "print(lispress_tokenizer.word_index[')'])\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<bos>', '(', 'Yield', ':output', '(', ':dayOfWeek', '(', 'Tomorrow', ')', ')', ')', '<eos>']\n",
            "1243286\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJOds3CQauZy"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUaSxENFZlX1"
      },
      "source": [
        "def tokenizeDialogues(dataset,tokenizer):\n",
        "    \"\"\"\n",
        "    Add a tokens2 attribute to the user_utterance in each turn with the token indexes\n",
        "    Add a tokens2_readable attribute to the user_utterance with the readable tokens\n",
        "    \"\"\"\n",
        "    for dialog in dataset:\n",
        "        for turn in dialog['turns']:\n",
        "            seq = tokenizer.texts_to_sequences([turn[\"user_utterance\"][\"original_text\"]])[0]\n",
        "            turn[\"user_utterance\"].update({\"tokens2\":seq,\"tokens2_readable\":[tokenizer.index_word[index] for index in seq]})\n",
        "            if \"tokens2_variable_readable\" in turn[\"user_utterance\"]:\n",
        "                del turn[\"user_utterance\"][\"tokens2_variable_readable\"]\n",
        "    tokenizedSet = [[ turn['user_utterance']['tokens2'] for turn in dialog['turns'] ]for dialog in dataset]\n",
        "    return tokenizedSet,dataset\n",
        "\n",
        "def tokenizeLispress(dataset,tokenizer):\n",
        "    \"\"\"\n",
        "    Adds lispress_tokens attribute in each turn which stores the indices of the lispress tokens\n",
        "    Adds lispress_tokens_readable attribute in each turn which stores the readable tokenized lispress\n",
        "    \"\"\"\n",
        "    for dialog in dataset:\n",
        "        for turn in dialog['turns']:\n",
        "            seq = tokenizer.texts_to_sequences([turn[\"lispress_tokenized\"]])[0]\n",
        "            turn.update({\"lispress_tokens\":seq,\"lispress_tokens_readable\":[tokenizer.index_word[index] for index in seq]})\n",
        "            if \"lispress_tokens_variable_readable\" in turn:\n",
        "                del turn[\"lispress_tokens_variable_readable\"]\n",
        "    tokenizedSet = [[ turn['lispress_tokens'] for turn in dialog['turns'] ]for dialog in dataset]\n",
        "    return tokenizedSet,dataset"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX8I5oXXZlX1"
      },
      "source": [
        "# Tokenize the user utterance (request) in train and validation set\n",
        "train_tokenized,train = tokenizeDialogues(train,tokenizer=tokenizer_user)\n",
        "valid_tokenized,valid = tokenizeDialogues(valid,tokenizer=tokenizer_user)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGU8gfyqZlX1"
      },
      "source": [
        "# Tokenize the lispress (response) in train and validation set\n",
        "train_tokenized_lispress,train_lispress = tokenizeLispress(train,tokenizer=lispress_tokenizer)\n",
        "valid_tokenized_lispress,valid_lispress = tokenizeLispress(valid,tokenizer=lispress_tokenizer)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsSxxa3oaxiA"
      },
      "source": [
        "def add_parameters(train,train_lispress):\n",
        "    variable_types = set()\n",
        "\n",
        "    for di,dialogue in enumerate(train_lispress):\n",
        "        for ti,turn in enumerate(dialogue[\"turns\"]):\n",
        "            var_idx={}\n",
        "            for i,token in enumerate(turn[\"lispress_tokens_readable\"]):\n",
        "                if not \"lispress_tokens_variable_readable\" in turn:\n",
        "                    turn.update({\"lispress_tokens_variable_readable\": list(turn[\"lispress_tokens_readable\"])})\n",
        "                if not \"tokens2_variable_readable\" in train[di][\"turns\"][ti][\"user_utterance\"]:\n",
        "                    train[di][\"turns\"][ti][\"user_utterance\"].update({\"tokens2_variable_readable\":list(train[di][\"turns\"][ti][\"user_utterance\"][\"tokens2_readable\"])})\n",
        "                if PARAMETER_REPLACEMENT==True and token == \"#\":\n",
        "                    variable_expression = turn[\"lispress_tokens_readable\"][i:turn[\"lispress_tokens_readable\"].index(')',i)+1]\n",
        "                    variable = []\n",
        "                    var_type = variable_expression[2]\n",
        "                    variable_types.add(var_type)\n",
        "                    first = 0\n",
        "                    last = -1\n",
        "                    try:\n",
        "                        first_index = variable_expression.index('\"')\n",
        "                        first = 4\n",
        "                        last = -2\n",
        "                    except:\n",
        "                        first = 3\n",
        "                        last=-1\n",
        "\n",
        "                    variable = variable_expression[first:last]\n",
        "\n",
        "                    for vi,var in enumerate(variable):\n",
        "                        if var_type == \"number\":\n",
        "                            try:\n",
        "                                var = str(int(float(var)))\n",
        "                            except Exception as e:\n",
        "                                print(e)\n",
        "                        # replace in user utterance\n",
        "                        if var in train[di][\"turns\"][ti][\"user_utterance\"][\"tokens2_readable\"]:\n",
        "                            if var_type not in var_idx:\n",
        "                                var_idx.update({var_type:0})\n",
        "                                placeholder = \"<\"+var_type+str(var_idx[var_type])+\">\"\n",
        "                                var_idx[var_type]+=1\n",
        "                                user_idx = train[di][\"turns\"][ti][\"user_utterance\"][\"tokens2_readable\"].index(var)\n",
        "                                train[di][\"turns\"][ti][\"user_utterance\"][\"tokens2_variable_readable\"][user_idx] = placeholder\n",
        "                                turn[\"lispress_tokens_variable_readable\"][i+first+vi] = placeholder\n",
        "                        else:\n",
        "                            if var_type == \"number\":\n",
        "                                for postfix in [\"pm\",\"am\",\"th\",\"st\",\"nd\"]:\n",
        "                                    if var+postfix in train[di][\"turns\"][ti][\"user_utterance\"][\"tokens2_readable\"]:\n",
        "                                        if var_type not in var_idx:\n",
        "                                            var_idx.update({var_type:0})\n",
        "                                            placeholder = \"<\"+var_type+str(var_idx[var_type])+\">\"\n",
        "                                            var_idx[var_type]+=1\n",
        "                                            user_idx = train[di][\"turns\"][ti][\"user_utterance\"][\"tokens2_readable\"].index(var+postfix)\n",
        "                                            train[di][\"turns\"][ti][\"user_utterance\"][\"tokens2_variable_readable\"][user_idx] = placeholder+postfix\n",
        "                                            turn[\"lispress_tokens_variable_readable\"][i+first+vi] = placeholder\n",
        "                            else:\n",
        "                              pass\n",
        "                                #print(\"not found in user utterance:\",var,var_type,train[di][\"turns\"][ti][\"user_utterance\"][\"tokens2_readable\"])\n",
        "                  #print(\"type:\",var_type,\"value:\",variable)\n",
        "                  #print(\"asd\")\n",
        "\n",
        "\n",
        "        #print(turn[\"lispress_tokens_variable_readable\"])\n",
        "        #print(train[di][\"turns\"][ti][\"user_utterance\"][\"tokens2_variable_readable\"])\n",
        "    return train, train_lispress, variable_types"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt5o892JnmZv"
      },
      "source": [
        "train_params,train_lispress_params,variable_types = add_parameters(train,train_lispress)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKnBmyL7i5Bj"
      },
      "source": [
        "valid_params, valid_lispress_params, _ = add_parameters(valid,valid_lispress)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3zxrZRUZlX1",
        "outputId": "cefc7491-c7c7-469d-a970-df18d5c2570d"
      },
      "source": [
        "# example: tokens generated from a message\n",
        "print(\"message:\",train[0][\"turns\"][0][\"user_utterance\"][\"original_text\"])\n",
        "print(\"tokens:\",train[0][\"turns\"][0][\"user_utterance\"][\"tokens2\"])\n",
        "print(\"readable tokens:\",train[0][\"turns\"][0][\"user_utterance\"][\"tokens2_readable\"])\n",
        "print(\"lispress tokens:\",valid[0][\"turns\"][0][\"lispress_tokens\"])\n",
        "print(\"lispress tokens readable:\",valid[0][\"turns\"][2][\"lispress_tokens_readable\"])\n",
        "\n",
        "print(\"lispress tokens with variables readable:\",train_params[1][\"turns\"][0][\"lispress_tokens_readable\"])\n",
        "print(\"lispress tokens with variables readable:\",train_params[1][\"turns\"][0][\"lispress_tokens_variable_readable\"])\n",
        "\n",
        "print(\"lispress tokens with variables readable:\",train_params[1][\"turns\"][0][\"user_utterance\"][\"tokens2_readable\"])\n",
        "print(\"lispress tokens with variables readable:\",train_params[0][\"turns\"][0][\"user_utterance\"][\"tokens2_variable_readable\"])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "message: what date is tomorrow?\n",
            "tokens: [18, 101, 12, 22]\n",
            "readable tokens: ['what', 'date', 'is', 'tomorrow']\n",
            "lispress tokens: [5, 1, 7, 8, 1, 29, 12, 1, 30, 10, 1, 9, 34, 1, 62, 1, 40, 33, 1, 14, 11, 1, 17, 1, 21, 1, 27, 10, 1, 25, 2, 26, 4, 1, 28, 3, 550, 3, 2, 2, 2, 2, 2, 2, 1, 40, 33, 1, 14, 11, 1, 17, 1, 21, 1, 27, 10, 1, 25, 2, 26, 4, 1, 28, 3, 191, 3, 2, 2, 2, 2, 2, 2, 2, 78, 1, 13, 1, 89, 4, 1, 15, 58, 2, 2, 2, 74, 1, 13, 4, 1, 59, 3, 211, 423, 1095, 3, 2, 2, 18, 1, 13, 1, 45, 16, 1, 44, 41, 4, 1, 38, 3, 122, 3, 2, 2, 22, 1, 42, 32, 4, 1, 15, 99, 2, 2, 2, 2, 19, 1, 13, 4, 1, 20, 3, 500, 3, 2, 2, 2, 2, 2, 2, 6]\n",
            "lispress tokens readable: ['<bos>', '(', 'yield', ':output', '(', 'createcommiteventwrapper', ':event', '(', 'createpreflighteventwrapper', ':constraint', '(', 'constraint[event]', ':attendees', '(', 'andconstraint', '(', 'andconstraint', '(', 'attendeelisthasrecipient', ':recipient', '(', 'execute', ':intension', '(', 'refer', '(', 'extensionconstraint', '(', 'recipientwithnamelike', ':constraint', '(', 'constraint[recipient]', ')', ':name', '#', '(', 'personname', '\"', 'dennis', '\"', ')', ')', ')', ')', ')', ')', '(', 'attendeelisthasrecipient', ':recipient', '(', 'execute', ':intension', '(', 'refer', '(', 'extensionconstraint', '(', 'recipientwithnamelike', ':constraint', '(', 'constraint[recipient]', ')', ':name', '#', '(', 'personname', '\"', 'gabriel', '\"', ')', ')', ')', ')', ')', ')', ')', '(', 'attendeelisthasrecipient', ':recipient', '(', 'execute', ':intension', '(', 'refer', '(', 'extensionconstraint', '(', 'recipientwithnamelike', ':constraint', '(', 'constraint[recipient]', ')', ':name', '#', '(', 'personname', '\"', 'max', '\"', ')', ')', ')', ')', ')', ')', ')', ':location', '(', '?=', '#', '(', 'locationkeyphrase', '\"', \"chili's\", 'on', '15th', 'street', '\"', ')', ')', ':start', '(', '?=', '(', 'nexttime', ':time', '(', 'hourminutepm', ':hours', '#', '(', 'number', '12', ')', ':minutes', '#', '(', 'number', '15', ')', ')', ')', ')', ':subject', '(', '?=', '#', '(', 'string', '\"', 'lunch', 'meeting', '\"', ')', ')', ')', ')', ')', ')', '<eos>']\n",
            "lispress tokens with variables readable: ['<bos>', '(', 'yield', ':output', '(', ':start', '(', 'singleton', '(', ':results', '(', 'findeventwrapperwithdefaults', ':constraint', '(', 'eventondate', ':date', '(', 'nextdow', ':dow', '#', '(', 'dayofweek', '\"', 'friday', '\"', ')', ')', ':event', '(', 'constraint[event]', ':attendees', '(', 'attendeelisthasrecipientconstraint', ':recipientconstraint', '(', 'recipientwithnamelike', ':constraint', '(', 'constraint[recipient]', ')', ':name', '#', '(', 'personname', '\"', 'jerri', 'skinner', '\"', ')', ')', ')', ')', ')', ')', ')', ')', ')', ')', '<eos>']\n",
            "lispress tokens with variables readable: ['<bos>', '(', 'yield', ':output', '(', ':start', '(', 'singleton', '(', ':results', '(', 'findeventwrapperwithdefaults', ':constraint', '(', 'eventondate', ':date', '(', 'nextdow', ':dow', '#', '(', 'dayofweek', '\"', 'friday', '\"', ')', ')', ':event', '(', 'constraint[event]', ':attendees', '(', 'attendeelisthasrecipientconstraint', ':recipientconstraint', '(', 'recipientwithnamelike', ':constraint', '(', 'constraint[recipient]', ')', ':name', '#', '(', 'personname', '\"', 'jerri', 'skinner', '\"', ')', ')', ')', ')', ')', ')', ')', ')', ')', ')', '<eos>']\n",
            "lispress tokens with variables readable: ['what', 'time', 'is', 'my', 'appointment', 'with', 'jerri', 'skinner', 'on', 'friday']\n",
            "lispress tokens with variables readable: ['what', 'date', 'is', 'tomorrow']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewTh0sYXvDdw"
      },
      "source": [
        "# user tokenizer on the parameterized input\n",
        "user_tokenizer_params = Tokenizer()\n",
        "dialogue_sent = [turn['user_utterance']['tokens2_variable_readable'] for dialog in train_params for turn in dialog['turns'] ]\n",
        "user_tokenizer_params.fit_on_texts(dialogue_sent)\n",
        "# lispress tokenizer on the parameterized programs\n",
        "lispress_tokenizer_params = Tokenizer()\n",
        "dialogue_sent_lispress_params = [turn['lispress_tokens_variable_readable'] for dialog in train_params for turn in dialog['turns']]\n",
        "lispress_tokenizer_params.fit_on_texts(dialogue_sent_lispress_params)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wb-4Bj5y7RYF",
        "outputId": "d34f445e-ac57-439b-f137-b7cd5aaefd7a"
      },
      "source": [
        "lispress_tokenizer_params.word_index[\"<bos>\"]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2HsSj0Xu1mn"
      },
      "source": [
        "def tokenizer_with_params(dataset,user_tokenizer,lispress_tokenizer):\n",
        "    for dialog in dataset:\n",
        "        for turn in dialog['turns']:\n",
        "            turn[\"user_utterance\"].update({\"tokens2_variable\":[user_tokenizer.word_index[word] if word in user_tokenizer.word_index else 0 for word in turn[\"user_utterance\"][\"tokens2_variable_readable\"]]})\n",
        "            turn.update({\"lispress_tokens_variable\":[lispress_tokenizer.word_index[word] if word in lispress_tokenizer.word_index else 0 for word in turn[\"lispress_tokens_variable_readable\"]]})\n",
        "    tokenized_train = [[ turn['user_utterance']['tokens2_variable'] for turn in dialog['turns'] ]for dialog in dataset]\n",
        "    tokenized_lispress = [[ turn['lispress_tokens_variable'] for turn in dialog['turns'] ]for dialog in dataset]\n",
        "    return tokenized_train,tokenized_lispress"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yC_nVuB6NYV"
      },
      "source": [
        "train_tokenized,train_tokenized_lispress = tokenizer_with_params(train_params,user_tokenizer_params,lispress_tokenizer_params)\n",
        "valid_tokenized,valid_tokenized_lispress = tokenizer_with_params(valid_params,user_tokenizer_params,lispress_tokenizer_params)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl2YnjLbZlX2"
      },
      "source": [
        "def flatten_nested_list(list0):\n",
        "    \"\"\"\n",
        "    Flatten the nested list's elements\n",
        "    Example:\n",
        "    [[1,2],[3]] => [1,2,3]\n",
        "    \"\"\"\n",
        "    return [element for nested in list0 for element in nested ]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuyPjf2GZlX2"
      },
      "source": [
        "### Create train,validation,test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRNpNPq3ZlX2"
      },
      "source": [
        "if RUN_MODE == RUN_FULLMODE:\n",
        "\n",
        "    MAX_TRAIN_DATA=-1 #how many train data will be used from the training set\n",
        "    MAX_VALID_DATA=-1001 # the last 99 elements of the validation data will be used as test data\n",
        "    MAX_TEST_DATA=1000\n",
        "\n",
        "elif RUN_MODE == RUN_TESTMODE:\n",
        "    MAX_TRAIN_DATA=20000 #limited training mode with 10000 data\n",
        "    MAX_VALID_DATA=2000 # the last 99 elements of the validation data will be used as test data\n",
        "    MAX_TEST_DATA=99"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD79DsYJZlX2"
      },
      "source": [
        "from copy import deepcopy\n",
        "def create_previous_program_input(data):\n",
        "    \"\"\"\n",
        "    from each dealogue -> remove the last element, and add a 0 to the beginning\n",
        "    \"\"\"\n",
        "    data_tmp = deepcopy(data)\n",
        "    for seqs in data_tmp:\n",
        "        del seqs[-1]\n",
        "        seqs.insert(0,[0])\n",
        "    return data_tmp"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYDKDAsiZlX2"
      },
      "source": [
        "# the user messages\n",
        "train_data = flatten_nested_list(train_tokenized)[:MAX_TRAIN_DATA]\n",
        "valid_data = flatten_nested_list(valid_tokenized)[:MAX_VALID_DATA]\n",
        "test_data = flatten_nested_list(valid_tokenized)[MAX_VALID_DATA:MAX_VALID_DATA+MAX_TEST_DATA]\n",
        "\n",
        "#the program stored in the last dialogue turn -> currently they are not taken into account\n",
        "train_data_di = flatten_nested_list(create_previous_program_input(train_tokenized_lispress))[:MAX_TRAIN_DATA]\n",
        "valid_data_di = flatten_nested_list(create_previous_program_input(valid_tokenized_lispress))[:MAX_VALID_DATA]\n",
        "test_data_di = flatten_nested_list(create_previous_program_input(valid_tokenized_lispress))[MAX_VALID_DATA:MAX_VALID_DATA+MAX_TEST_DATA]\n",
        "\n",
        "#the current program\n",
        "train_data_y = flatten_nested_list(train_tokenized_lispress)[:MAX_TRAIN_DATA]\n",
        "valid_data_y = flatten_nested_list(valid_tokenized_lispress)[:MAX_VALID_DATA]\n",
        "test_data_y = flatten_nested_list(valid_tokenized_lispress)[MAX_VALID_DATA:MAX_VALID_DATA+MAX_TEST_DATA]\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "vTPBZfVPf8SX",
        "outputId": "c06e7095-522a-4cc5-9b0f-e661483e4446"
      },
      "source": [
        "lens = []\n",
        "for l in [50,100,150,200,250,600]:\n",
        "  lens.append(len([x for x in train_data_y if len(x) < l]))\n",
        "plt.plot([50,100,150,200,250,600],lens)\n",
        "\n",
        "train_ids = [idx for idx,x in enumerate(train_data_y) if len(x) < 100 ]\n",
        "valid_ids = [idx for idx,x in enumerate(valid_data_y) if len(x) < 100]\n",
        "test_ids = [idx for idx,x in enumerate(test_data_y) if len(x) < 100]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAa6klEQVR4nO3de4xc5Znn8e/T3Xbb7Xu728Zx2/iCNQxhuRiPcZSZkRO0YNhozDJO1sxKeLNWrEwcKZF2NQFFGrQwSDBZLRt2EyZo8WBGGQjDbAYvA3G8DhOkHXExMQFzG7rKYLfBrmq73XZV39xdz/5Rb5miqeq2u+vSder3kUp16jmnTr2vafrX57yn3mPujoiISCEN1W6AiIhMXQoJEREpSiEhIiJFKSRERKQohYSIiBTVVO0GlFpbW5uvWLGi2s0QEakpr732Wre7t4+uRy4kVqxYwYEDB6rdDBGRmmJmHxaq63STiIgUpZAQEZGiFBIiIlKUQkJERIpSSIiISFEKCRERKUohISIiRUXuexJSPZmMczI9xIkzA5wZOIc7ZNzJhGd3J5P5pOZ567LrC2zvo7bP5K/PW8fkp7yfSrPml2oK/1L1qRS7KV1bps6/Tcl+ZEr0j/Nv13awsm1WSfaVo5CQcQ2PZOhODZE4O0DizCAnwnPi7CDJswOcODNI4uwA3akhRjJT6DetSA0xm/w+1l66QCEhpTM0nCGZGiRxJvuLPnl2gMTZQU6cyT7nguBkerDgHzpts6fTPmcGi+Y0c/klc1g8dwaL5jazaE4z82ZOp7HBaDAwyz43mNFghuWWG3K13DafbGd52xfcR/57sZL8Dwal+R8Vsm2a9D5K1pYS7acEDSpdW0q1n1K1KLoUEnXgeO8Af/vKEY719JM4O0AyBEFP37nPbNtg0Da7mUVzm1kybwZXL5t3PggWz80+L5rbTNvsZqY1akhLJOoUEhHWPzTCIy/G+atfxxgcHgl/6c9gWWsL1126gEVzZrB4bnP46z8bAAtnN9PYoL+uRCRLIRFB7s6e337EA8+/y0e9A9zyry7hrpt/l2WtLdVumojUGIVExBw80sO9z77Nb46c5sqlc3nw313D9asWVrtZIlKjFBIR8XFvP3/5i/f4+cFjtM9p5i+3XMWWtR006NSRiEyCQqLG5Y87jLiz80ur+dONlzG7Wf9pRWTy9JukRuXGHe5//l0+7h3g31y1hDs3Xa5xBxEpKYVEDTp4pId7nn2bg2Hc4Ydbr2X9ytZqN0tEIkghUUNGjzv8YMtV/LHGHUSkjBQSNaB/aISfvBjjr34dI+Pw7S9dxjc3rta4g4iUnX7LTGGZTPi+wy807iAi1THuvApmtsvMEmZ2KK92r5m9YWavm9kvzexzoW5m9pCZdYb1a/Pes83M3g+PbXn168zszfCehyxMpmJmrWa2L2y/z8wWlLbrU9tvjvRw28P/zHd/9jpts5v5u29+gR/9yVoFhIhU1IVMvvMYsGlU7QfufpW7XwM8C/x5qN8MrAmPHcDDkP2FD9wNXA+sB+7O+6X/MPCNvPflPutOYL+7rwH2h9eR99Hpfr775EFu+/E/89Hpfv7rV6/mmZ1f5PdWaGBaRCpv3NNN7v6ima0YVTuT93IWn0yrvhl43LOT4b9kZvPNbAmwEdjn7qcAzGwfsMnM/gmY6+4vhfrjwK3A82FfG8N+dwP/BHzvYjtYK/qGhvnJr+P85MVPxh3+dONqZmncQUSqaMK/gczsPuAOoBf4UigvBY7mbdYVamPVuwrUARa7+8dh+TiweKJtncpy4w73P/8ux88M8JWrlnDnzZfTsUCnlUSk+iYcEu7+feD7ZnYX8G2yp5PKwt3dzIrezcbMdpA9vcXy5cvL1YyS+82RHu75P2/z+tHTXNUxj//5J9eyTqeVRGQKKcUNAX4K/HFYPgYsy1vXEWpj1TsK1AFOhFNVhOdEsQa4+yPuvs7d17W3t0+iK5Vz3z++/alxh3/41hcVECIy5UwoJMxsTd7LzcC7YXkPcEe4ymkD0BtOGe0FbjSzBWHA+kZgb1h3xsw2hKua7gCeydtX7iqobXn1mnduJMNf/78PuOnzi3nhP29ky3X6QpyITE3jnm4ysyfIDiC3mVkX2dNKt5jZ7wAZ4EPgm2Hz54BbgE6gD/g6gLufMrN7gVfDdvfkBrGBb5G9gmom2QHr50P9fuApM9sePuNrE+7lFHPkVB/DGefGKy7RwLSITGkXcnXT7QXKjxbZ1oGdRdbtAnYVqB8ArixQPwncMF77alE8mQZgVXtpb1guIlJquklxFcSSKQBWtc+ucktERMamkKiCeDJF+5xm5s2cVu2miIiMSSFRBbFkmlVtOtUkIlOfQqIK4skUqxfpVJOITH0KiQo7lR6ip++cjiREpCYoJCosN2itIwkRqQUKiQqLh5C4TFc2iUgNUEhUWCyZZnpTA5+bP7PaTRERGZdCosLiyRSr2mbRqGk4RKQGKCQqLJZM65vWIlIzFBIVNDSc4cipPlZrPEJEaoRCooKOnEozknGFhIjUDIVEBXUmNLGfiNQWhUQFxbs1sZ+I1BaFRAXFEmkWz21mtu4hISI1QiFRQbFkSuMRIlJTFBIV4u7Zif0UEiJSQxQSFdKdGuLMwLAGrUWkpigkKiQ3Z5OOJESkligkKiSm+1qLSA1SSFRILJlixrQGPjdPE/uJSO1QSFRIdmK/2TRoYj8RqSEKiQrRxH4iUosUEhUwcG6Erh5N7CcitUchUQEfnuwj4xq0FpHao5CogJgufxWRGqWQqIDcdyR0JCEitUYhUQGxZJrPzZtBy3RN7CcitUUhUQHxZIrVi3SqSURqj0KizNw9e/lrm041iUjtUUiUWeLsIKnBYR1JiEhNUkiUma5sEpFappAoM03sJyK1TCFRZvFkipbpjVwyd0a1myIictHGDQkz22VmCTM7lFf7gZm9a2ZvmNnPzWx+3rq7zKzTzN4zs5vy6ptCrdPM7syrrzSzl0P9Z2Y2PdSbw+vOsH5FqTpdSbk5m8w0sZ+I1J4LOZJ4DNg0qrYPuNLdrwL+BbgLwMyuALYCnw/v+bGZNZpZI/Aj4GbgCuD2sC3AA8CD7n4Z0ANsD/XtQE+oPxi2qzmxhG5ZKiK1a9yQcPcXgVOjar909+Hw8iWgIyxvBp5090F3Pwx0AuvDo9Pd4+4+BDwJbLbsn9dfBp4O798N3Jq3r91h+WngBquxP8f7h0b4qLdfISEiNasUYxL/EXg+LC8Fjuat6wq1YvWFwOm8wMnVP7WvsL43bP8ZZrbDzA6Y2YFkMjnpDpXK4e40ron9RKSGTSokzOz7wDDw09I0Z2Lc/RF3X+fu69rb26vZlE+Jd+vyVxGpbROeTMjM/gPwFeAGd/dQPgYsy9usI9QoUj8JzDezpnC0kL99bl9dZtYEzAvb14xYIo0ZrNS3rUWkRk3oSMLMNgF/BvyRu/flrdoDbA1XJq0E1gCvAK8Ca8KVTNPJDm7vCeHyArAlvH8b8EzevraF5S3Ar/LCqCbEkimWzp/JjGmN1W6KiMiEjHskYWZPABuBNjPrAu4mezVTM7AvjCW/5O7fdPe3zOwp4G2yp6F2uvtI2M+3gb1AI7DL3d8KH/E94Ekz+wvgIPBoqD8K/I2ZdZIdON9agv5WVLxbVzaJSG0bNyTc/fYC5UcL1HLb3wfcV6D+HPBcgXqc7NVPo+sDwFfHa99U5e7Ek2l+b0VrtZsiIjJh+sZ1mRw/M0Df0IiOJESkpikkyiSW0JxNIlL7FBJlkpv99TIdSYhIDVNIlEk8mWJOcxPtc5qr3RQRkQlTSJSJJvYTkShQSJRJPKnLX0Wk9ikkyiA9OMxHvQMatBaRmqeQKIPD3dkrm3QkISK1TiFRBufva71IISEitU0hUQaxZJoGg0sXtlS7KSIik6KQKIN4MsWy1haamzSxn4jUNoVEGcSSaVZpenARiQCFRIllMs5hzf4qIhGhkCixj3r7GTiX0aC1iESCQqLEYskwsZ9ON4lIBCgkSiyuy19FJEIUEiUWS6aYO6OJhbOmV7spIiKTppAosVgizepFszWxn4hEgkKixHRfaxGJEoVECZ0dOMeJM4Oa2E9EIkMhUUKa2E9EokYhUULnJ/bTkYSIRIRCooRiiTSNDcbyVoWEiESDQqKE4t0pLm1tYXqT/llFJBr026yEYom0Bq1FJFIUEiUyknEOn0xr0FpEIkUhUSLHevoZGs7oSEJEIkUhUSKfXNmkIwkRiQ6FRIkoJEQkihQSJRJLplnQMo0FmthPRCJEIVEi8aTmbBKR6FFIlEgsqctfRSR6FBIl0Nt/ju7UoI4kRCRyFBIlENegtYhE1LghYWa7zCxhZofyal81s7fMLGNm60Ztf5eZdZrZe2Z2U159U6h1mtmdefWVZvZyqP/MzKaHenN43RnWryhFh8vh/H2tdbpJRCLmQo4kHgM2jaodAm4DXswvmtkVwFbg8+E9PzazRjNrBH4E3AxcAdwetgV4AHjQ3S8DeoDtob4d6An1B8N2U1I8mWJao7GstaXaTRERKalxQ8LdXwROjaq94+7vFdh8M/Ckuw+6+2GgE1gfHp3uHnf3IeBJYLNl7/H5ZeDp8P7dwK15+9odlp8GbrApek/QWDLF8tYWpjXq7J2IREupf6stBY7mve4KtWL1hcBpdx8eVf/UvsL63rD9Z5jZDjM7YGYHkslkibpy4WJJzdkkItEUiT993f0Rd1/n7uva29sr+tnDIxk+PJlm9SKFhIhET6lD4hiwLO91R6gVq58E5ptZ06j6p/YV1s8L208pR3v6OTfirGrToLWIRE+pQ2IPsDVcmbQSWAO8ArwKrAlXMk0nO7i9x90deAHYEt6/DXgmb1/bwvIW4Fdh+ynl/OWvOpIQkQhqGm8DM3sC2Ai0mVkXcDfZgez/AbQD/2hmr7v7Te7+lpk9BbwNDAM73X0k7OfbwF6gEdjl7m+Fj/ge8KSZ/QVwEHg01B8F/sbMOsPnbS1Fh0vt/MR+bQoJEYmecUPC3W8vsurnRba/D7ivQP054LkC9TjZq59G1weAr47XvmqLJdK0zZ7OvJZp1W6KiEjJRWLgupri3SlW6comEYkohcQkZS9/1aC1iESTQmISetJDnEoP6TsSIhJZColJiHdnB601Z5OIRJVCYhJiiezEfjqSEJGoUkhMQqw7xfTGBjoWaGI/EYkmhcQkxBJpVrS10NgwJecdFBGZNIXEJMS7dV9rEYk2hcQEnRvJcORknwatRSTSFBIT9OHJPoYzriMJEYk0hcQE6b7WIlIPFBITpPtai0g9UEhMUDyZYtGcZubM0MR+IhJdCokJiiVTOooQkchTSEyAu+u+1iJSFxQSE3AqPURv/zmFhIhEnkJiAjRoLSL1QiExAbr8VUTqhUJiAmLJFM1NDSydP7PaTRERKSuFxATEkmlWts2iQRP7iUjEKSQmIJ5MsXqRTjWJSPQpJC7S4PAIR071sbpNg9YiEn0KiYt05GQfGUdHEiJSFxQSFykWrmxa1aaQEJHoU0hcJH1HQkTqiULiIsWSKZbMm8Gs5qZqN0VEpOwUEhcplkzrKEJE6oZC4iK4e/byV33TWkTqhELiIiRTg5wdGGaVLn8VkTqhkLgIsUR20FqXv4pIvVBIXIR4tyb2E5H6opC4CLFEmpnTGrlk7oxqN0VEpCIUEhch3p29Zakm9hOReqGQuAjZ+1rrVJOI1I9xQ8LMdplZwswO5dVazWyfmb0fnheEupnZQ2bWaWZvmNnavPdsC9u/b2bb8urXmdmb4T0PmZmN9RnVMnBuhK6eflbrOxIiUkcu5EjiMWDTqNqdwH53XwPsD68BbgbWhMcO4GHI/sIH7gauB9YDd+f90n8Y+Ebe+zaN8xlV8cHJNO4atBaR+jJuSLj7i8CpUeXNwO6wvBu4Na/+uGe9BMw3syXATcA+dz/l7j3APmBTWDfX3V9ydwceH7WvQp9RFbnLX/VtaxGpJxMdk1js7h+H5ePA4rC8FDiat11XqI1V7ypQH+szPsPMdpjZATM7kEwmJ9Cd8cU1+6uI1KFJD1yHIwAvQVsm/Bnu/oi7r3P3de3t7WVpQyyZYun8mcyc3liW/YuITEUTDYkT4VQR4TkR6seAZXnbdYTaWPWOAvWxPqMq4t2a2E9E6s9EQ2IPkLtCaRvwTF79jnCV0wagN5wy2gvcaGYLwoD1jcDesO6MmW0IVzXdMWpfhT6j4tydWEIT+4lI/Rn3pghm9gSwEWgzsy6yVyndDzxlZtuBD4Gvhc2fA24BOoE+4OsA7n7KzO4FXg3b3ePuucHwb5G9gmom8Hx4MMZnVNyJM4Okh0Z0+auI1J1xQ8Ldby+y6oYC2zqws8h+dgG7CtQPAFcWqJ8s9BnVkBu01pGEiNQbfeP6Apy/r7VCQkTqjELiAsSSaWZNb2Tx3OZqN0VEpKIUEhcglkyxetFswowhIiJ1QyFxAeLJtO5GJyJ1SSExjv6hEY6d7tegtYjUJYXEOHJ3o9OgtYjUI4XEOOLJ3H2tdbpJROqPQmIcsWQKM1ixUCEhIvVHITGOWDJNx4KZzJimif1EpP4oJMYRT2rOJhGpXwqJMWQyHi5/VUiISH1SSIzh+JkB+s+NaNBaROqWQmIMMU3sJyJ1TiExhlgi9x0JHUmISH1SSIwh3p1mzowm2mdrYj8RqU8KiTHEkilWtWtiPxGpXwqJMcSTad2NTkTqmkKiiNTgMB/3DmjQWkTqmkKiiMO5OZt0JCEidUwhUURu9lcdSYhIPVNIFBFLpGgwWL6wpdpNERGpGoVEEbHuNMtbW2hu0sR+IlK/FBJFxBKa2E9ERCFRQCbjHO5O65vWIlL3FBIFHDvdz+BwRkcSIlL3FBIF5Cb2032tRaTeKSQKiOs7EiIigEKioFgyxbyZ02idNb3aTRERqSqFRAGxZIrV7bM0sZ+I1D2FRAHZif00HiEiopAY5ezAORJnBzVoLSKCQuIzNGgtIvIJhcQouvxVROQTColRYskUTQ3GpZrYT0RkciFhZt8xs0Nm9paZfTfUWs1sn5m9H54XhLqZ2UNm1mlmb5jZ2rz9bAvbv29m2/Lq15nZm+E9D1kFLjeKJ9MsX9jCtEblp4jIhH8TmtmVwDeA9cDVwFfM7DLgTmC/u68B9ofXADcDa8JjB/Bw2E8rcDdwfdjX3blgCdt8I+99myba3gsVS6ZY1aZTTSIiMLkjid8FXnb3PncfBn4N3AZsBnaHbXYDt4blzcDjnvUSMN/MlgA3Afvc/ZS79wD7gE1h3Vx3f8ndHXg8b19lMZJxPujuY/UiDVqLiMDkQuIQ8AdmttDMWoBbgGXAYnf/OGxzHFgclpcCR/Pe3xVqY9W7CtQ/w8x2mNkBMzuQTCYn3KGunj6GRjKs1pGEiAgwiZBw93eAB4BfAr8AXgdGRm3jgE+mgRfYlkfcfZ27r2tvb5/wfnJXNulIQkQka1Kjs+7+qLtf5+5/CPQA/wKcCKeKCM+JsPkxskcaOR2hNla9o0C9bHLfkdCYhIhI1mSvbloUnpeTHY/4W2APkLtCaRvwTFjeA9wRrnLaAPSG01J7gRvNbEEYsL4R2BvWnTGzDeGqpjvy9lUWsWSK1lnTWaCJ/UREAGia5Pv/3swWAueAne5+2szuB54ys+3Ah8DXwrbPkR236AT6gK8DuPspM7sXeDVsd4+7nwrL3wIeA2YCz4dH2cSSaX3TWkQkz6RCwt3/oEDtJHBDgboDO4vsZxewq0D9AHDlZNp4MeLJFDdcvnj8DUVE6oS+MRb09p2jOzWkQWsRkTwKiSDWHa5s0pxNIiLnKSSCWEIT+4mIjKaQCOLdaaY1GssWzKx2U0REpgyFRHBpawu3XdtBkyb2ExE5b7KXwEbG1vXL2bp+ebWbISIypejPZhERKUohISIiRSkkRESkKIWEiIgUpZAQEZGiFBIiIlKUQkJERIpSSIiISFGWncE7OswsSfY+FrWgDeiudiPKJMp9g2j3T32rXZPp36Xu/pn7P0cuJGqJmR1w93XVbkc5RLlvEO3+qW+1qxz90+kmEREpSiEhIiJFKSSq65FqN6CMotw3iHb/1LfaVfL+aUxCRESK0pGEiIgUpZAQEZGiFBJlZGa7zCxhZofyaq1mts/M3g/PC0LdzOwhM+s0szfMbG31Wj42M1tmZi+Y2dtm9paZfSfUa75vAGY2w8xeMbPfhv79l1BfaWYvh378zMymh3pzeN0Z1q+oZvsvhJk1mtlBM3s2vI5S3z4wszfN7HUzOxBqUfnZnG9mT5vZu2b2jpl9odx9U0iU12PAplG1O4H97r4G2B9eA9wMrAmPHcDDFWrjRAwD/8ndrwA2ADvN7Aqi0TeAQeDL7n41cA2wycw2AA8AD7r7ZUAPsD1svx3oCfUHw3ZT3XeAd/JeR6lvAF9y92vyvjMQlZ/NHwK/cPfLgavJ/jcsb9/cXY8yPoAVwKG81+8BS8LyEuC9sPwT4PZC2031B/AM8K8j2rcW4DfA9WS/ydoU6l8A9oblvcAXwnJT2M6q3fYx+tQRfpl8GXgWsKj0LbTzA6BtVK3mfzaBecDh0f/+5e6bjiQqb7G7fxyWjwOLw/JS4Gjedl2hNqWF0w/XAi8Tob6F0zGvAwlgHxADTrv7cNgkvw/n+xfW9wILK9vii/LfgT8DMuH1QqLTNwAHfmlmr5nZjlCLws/mSiAJ/HU4Vfi/zGwWZe6bQqKKPBvvNXsNspnNBv4e+K67n8lfV+t9c/cRd7+G7F/d64HLq9ykkjCzrwAJd3+t2m0po99397VkT7fsNLM/zF9Zwz+bTcBa4GF3vxZI88mpJaA8fVNIVN4JM1sCEJ4ToX4MWJa3XUeoTUlmNo1sQPzU3f93KEeib/nc/TTwAtlTMPPNrCmsyu/D+f6F9fOAkxVu6oX6IvBHZvYB8CTZU04/JBp9A8Ddj4XnBPBzsiEfhZ/NLqDL3V8Or58mGxpl7ZtCovL2ANvC8jay5/Nz9TvCFQkbgN68Q8gpxcwMeBR4x93/W96qmu8bgJm1m9n8sDyT7HjLO2TDYkvYbHT/cv3eAvwq/EU35bj7Xe7e4e4rgK1k2/rviUDfAMxslpnNyS0DNwKHiMDPprsfB46a2e+E0g3A25S7b9UejInyA3gC+Bg4R/avgO1kz+fuB94H/i/QGrY14Edkz32/CayrdvvH6Nfvkz2kfQN4PTxuiULfQnuvAg6G/h0C/jzUVwGvAJ3A3wHNoT4jvO4M61dVuw8X2M+NwLNR6lvox2/D4y3g+6EelZ/Na4AD4WfzH4AF5e6bpuUQEZGidLpJRESKUkiIiEhRCgkRESlKISEiIkUpJEREpCiFhIiIFKWQEBGRov4/I1X0+ntqPLEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzIu0aKZhYIR",
        "outputId": "48ae3180-e4e4-4c74-b1c4-bec903af8d1d"
      },
      "source": [
        "print(len(train_ids),len(valid_ids),len(test_ids))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "129436 13291 973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WisaOUBYiXyA"
      },
      "source": [
        "train_data = [x for idx,x in enumerate(train_data) if idx in train_ids]\n",
        "valid_data = [x for idx,x in enumerate(valid_data) if idx in valid_ids]\n",
        "test_data = [x for idx,x in enumerate(test_data) if idx in test_ids]\n",
        "\n",
        "#the program stored in the last dialogue turn -> currently they are not taken into account\n",
        "train_data_di = [x for idx,x in enumerate(train_data_di) if idx in train_ids]\n",
        "valid_data_di = [x for idx,x in enumerate(valid_data_di) if idx in valid_ids]\n",
        "test_data_di = [x for idx,x in enumerate(test_data_di) if idx in test_ids]\n",
        "\n",
        "#the current program\n",
        "train_data_y = [x for idx,x in enumerate(train_data_y) if idx in train_ids]\n",
        "valid_data_y = [x for idx,x in enumerate(valid_data_y) if idx in valid_ids]\n",
        "test_data_y = [x for idx,x in enumerate(test_data_y) if idx in test_ids]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "verlxgr1cwsv",
        "outputId": "cabe2b88-043f-4b2c-812a-a8ffa68d2fe9"
      },
      "source": [
        "# the length of the decoder input and output\n",
        "MAX_LEN_DEC=max([len(i) for i in train_data_y])\n",
        "print(MAX_LEN_DEC)\n",
        "\n",
        "MAX_LEN_ENC=max([len(i) for i in train_data])\n",
        "print(MAX_LEN_ENC)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99\n",
            "104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bnKoznPkyk5",
        "outputId": "58b9448c-cbc8-4600-ed89-965dc619eb3f"
      },
      "source": [
        "len(test_data),len(test_data_y)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(973, 973)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73DiHUxAZlX2"
      },
      "source": [
        "\n",
        "\n",
        "# generate encoder input, decoder input and decoder target sequences\n",
        "def generate_dataset(encoder_input,previous_program,current_program):\n",
        "    \"\"\"\n",
        "    Creates the encoder input, decoder input and decoder output.\n",
        "    For each target program create len(program)-1 training data:\n",
        "    #   |Encoder input | Decoder input | Decoder output\n",
        "    1.  |input sequence 1 | current program 1 first token | current program 1 second token\n",
        "    2.  |input sequence 1 | current program 1 first two tokens | current program 1 2. and 3. tokens\n",
        "    ...\n",
        "    n.  |input sequence 1 | current program 1 n-MAX_LEN_DEC-1 -> n-1 tokens | current program 1 n-MAX_LEN_DEC -> n tokens\n",
        "    n+1.|input sequence 2 | ...\n",
        "    \n",
        "    Parameters:\n",
        "    encoder_input (list): list of input sequences\n",
        "    previous_program (list): list of previous programs\n",
        "    current_program (list): list of current programs (target)\n",
        "\n",
        "    Returns:\n",
        "    data: generated encoder input\n",
        "    data_di: generated decoder input\n",
        "    data_y: generated decoder output\n",
        "    \"\"\"\n",
        "    data,data_di,data_y = [],[],[]\n",
        "    for i,sent in enumerate(current_program):\n",
        "        data.append(encoder_input[i])\n",
        "        data_di.append(current_program[i])\n",
        "        data_y.append(current_program[i][1:])\n",
        "    return data,data_di,data_y"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_cnSL2iZlX2"
      },
      "source": [
        "train_data_new,train_data_new_di,train_data_new_y = None,None,None\n",
        "valid_data_new,valid_data_new_di,valid_data_new_y = None,None,None\n",
        "test_data_new,test_data_new_di,test_data_new_y = None,None,None"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Gjsf40jZlX2"
      },
      "source": [
        "# generate the training data\n",
        "train_data_new,train_data_new_di,train_data_new_y = generate_dataset(train_data,train_data_di,train_data_y)\n",
        "valid_data_new,valid_data_new_di,valid_data_new_y = generate_dataset(valid_data,valid_data_di,valid_data_y)\n",
        "test_data_new,test_data_new_di,test_data_new_y = generate_dataset(test_data,test_data_di,test_data_y)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HMckg0kL7-T",
        "outputId": "5e4794c6-b7a5-4b7e-90cd-fdeb488b067a"
      },
      "source": [
        "train_data_new[:10]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[18, 101, 12, 22],\n",
              " [18, 46, 41, 1, 40, 12, 22],\n",
              " [23, 163, 32],\n",
              " [18, 38, 12, 7, 31, 5, 488, 526, 8, 39],\n",
              " [14, 11, 25, 36, 31, 5, 488, 526, 6, 112, 34],\n",
              " [3, 37, 16, 2, 71, 54, 95],\n",
              " [44, 51],\n",
              " [14, 11, 1075, 47, 5, 374, 17, 204, 178],\n",
              " [949, 1, 496, 160, 33, 1284, 47, 17, 174, 374],\n",
              " [25, 544, 110, 5103, 3813, 2477, 640, 289, 470, 417]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBfxqNFYMB62",
        "outputId": "3da28e91-7923-4e38-a35d-b7320a378a18"
      },
      "source": [
        "train_data_new_di[:1]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 1, 7, 8, 1, 60, 2, 2, 6]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FC4KZ93daGf",
        "outputId": "73841d34-65ca-4b76-a979-17b043905fec"
      },
      "source": [
        "train_data_new_y[:1]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 7, 8, 1, 60, 2, 2, 6]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqUUiOoxZlX2"
      },
      "source": [
        "### Padding encoder and decoder inputs, and decoder output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia1L6mQyZlX2"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIVIj5oEZlX2"
      },
      "source": [
        "MAX_LEN=MAX_LEN_ENC # length of the encoder input\n",
        "\n",
        "# padding the encoder, and decoder inputs\n",
        "# padding will be added to the end of the encoder input (if needed)\n",
        "# padding will be added to the begining of the decoder inputs and outputs (if needed)\n",
        "\n",
        "encoder_train = pad_sequences(train_data_new,maxlen=MAX_LEN_ENC,dtype=\"int32\",padding='post', truncating='post')\n",
        "decoder_train = pad_sequences(train_data_new_y,maxlen=MAX_LEN_DEC,dtype=\"int32\",padding='post', truncating='post')\n",
        "decoder_train_input = pad_sequences(train_data_new_di,maxlen=MAX_LEN_DEC,dtype=\"int32\",padding='post', truncating='post')\n",
        "\n",
        "encoder_valid = pad_sequences(valid_data_new,maxlen=MAX_LEN_ENC,dtype=\"int32\",padding='post', truncating='post')\n",
        "decoder_valid = pad_sequences(valid_data_new_y,maxlen=MAX_LEN_DEC,dtype=\"int32\",padding='post', truncating='post')\n",
        "decoder_valid_input = pad_sequences(valid_data_new_di,maxlen=MAX_LEN_DEC,dtype=\"int32\",padding='post', truncating='post')\n",
        "\n",
        "encoder_test = pad_sequences(test_data_new,maxlen=MAX_LEN_ENC,dtype=\"int32\",padding='post', truncating='post')\n",
        "decoder_test = pad_sequences(test_data_new_y,maxlen=MAX_LEN_DEC,dtype=\"int32\",padding='post', truncating='post')\n",
        "decoder_test_input = pad_sequences(test_data_new_di,maxlen=MAX_LEN_DEC,dtype=\"int32\",padding='post', truncating='post')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2CT4l-FZlX2"
      },
      "source": [
        "### Create embedding matrices for the embedding layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS5qXSMFwdLn"
      },
      "source": [
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvTxNVDBZlX2"
      },
      "source": [
        "# load the glove vector representations\n",
        "GLOVE_DIR=\"glove\"\n",
        "embeddings_index = {}\n",
        "with open(os.path.join(root_path,GLOVE_DIR,\"glove.6B.100d.txt\"),'rb') as f:\n",
        "    for line in f.readlines():\n",
        "        values = line.split()\n",
        "        word = str(values[0],encoding=\"utf8\")\n",
        "        coefs = np.asanyarray(values[1:], dtype=\"float32\")\n",
        "        embeddings_index[word] = coefs"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnzcCgZoZlX2"
      },
      "source": [
        "# create embedding matrix for the encoder\n",
        "embedding_dimension = 100\n",
        "DECODING_DEPTH = len(lispress_tokenizer.word_index)+1\n",
        "embedding_matrix_encoder = np.zeros((len(tokenizer_user.word_index)+1,embedding_dimension))\n",
        "for word, i in tokenizer_user.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix_encoder[i] = embedding_vector\n",
        "\n",
        "# create embedding matrix for the decoder\n",
        "embedding_matrix_decoder = np.zeros((DECODING_DEPTH,embedding_dimension))\n",
        "for word, i in lispress_tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None and i < DECODING_DEPTH:\n",
        "        embedding_matrix_decoder[i] = embedding_vector"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBnsh0CgZlX2"
      },
      "source": [
        "def decoder_output_creater(decoder_input_data, num_samples, MAX_LEN, VOCAB_SIZE):  \n",
        "    \"\"\"\n",
        "    Creates the one hot encoded version of the data\n",
        "    \"\"\"\n",
        "    decoder_output_data = np.zeros((num_samples, MAX_LEN, VOCAB_SIZE), dtype=\"float32\")\n",
        "\n",
        "    for i, seqs in enumerate(decoder_input_data):\n",
        "        for j, seq in enumerate(seqs):\n",
        "            if j > 0 and seq < VOCAB_SIZE:\n",
        "                decoder_output_data[i][j][seq] = 1.\n",
        "\n",
        "    return decoder_output_data"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjYxUIeiZlX3"
      },
      "source": [
        "### Create seq2seq model\n",
        "\n",
        "Simple sequence to sequence model with LSTM encoder and decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxQqPzbTZlX3"
      },
      "source": [
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import Embedding,Dense,Activation,Concatenate,Bidirectional\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, BatchNormalization"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6VY1lwcJDhU"
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import initializers, regularizers, constraints\n",
        "\n",
        "\n",
        "\n",
        "class Attention(Layer):\n",
        "    def __init__(self, step_dim,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "        \n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 initializer=self.init,\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight(shape=(input_shape[1],),\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     initializer='zero',\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "        eij = K.tanh(eij)\n",
        "        a = K.exp(eij)\n",
        "        if mask is not None:\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return weighted_input\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[1],input_shape[-1]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3nhnjJnE5o3"
      },
      "source": [
        "def dot_product(x, kernel):\n",
        "   if K.backend() == 'tensorflow':\n",
        "       return K.squeeze(K.dot(x, K.expand_dims(kernel)),axis=-1)\n",
        "   else:\n",
        "       return K.dot(x, kernel)\n",
        "\n",
        "class AttentionWithContext(Layer):\n",
        "    \"\"\"\n",
        "Attention operation, with a context/query vector, for temporal data.\n",
        "\n",
        "\"Hierarchical Attention Networks for Document Classification\"\n",
        "by using a context vector to assist the attention\n",
        "# Input shape\n",
        "    3D tensor with shape: (samples, steps, features).\n",
        "# Output shape\n",
        "    2D tensor with shape: (samples, features).\n",
        "     \"\"\"\n",
        "\n",
        "def __init__(self,\n",
        "             W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
        "             W_constraint=None, u_constraint=None, b_constraint=None,\n",
        "             bias=True, **kwargs):\n",
        "\n",
        "    self.supports_masking = True\n",
        "    self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "    self.W_regularizer = regularizers.get(W_regularizer)\n",
        "    self.u_regularizer = regularizers.get(u_regularizer)\n",
        "    self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "    self.W_constraint = constraints.get(W_constraint)\n",
        "    self.u_constraint = constraints.get(u_constraint)\n",
        "    self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "    self.bias = bias\n",
        "    super(AttentionWithContext, self).__init__(**kwargs)\n",
        "\n",
        "def build(self, input_shape):\n",
        "    assert len(input_shape) == 3\n",
        "\n",
        "    self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
        "                             initializer=self.init,\n",
        "                             name='{}_W'.format(self.name),\n",
        "                             regularizer=self.W_regularizer,\n",
        "                             constraint=self.W_constraint)\n",
        "    if self.bias:\n",
        "        self.b = self.add_weight((input_shape[-1],),\n",
        "                                 initializer='zero',\n",
        "                                 name='{}_b'.format(self.name),\n",
        "                                 regularizer=self.b_regularizer,\n",
        "                                 constraint=self.b_constraint)\n",
        "\n",
        "    self.u = self.add_weight((input_shape[-1],),\n",
        "                             initializer=self.init,\n",
        "                             name='{}_u'.format(self.name),\n",
        "                             regularizer=self.u_regularizer,\n",
        "                             constraint=self.u_constraint)\n",
        "\n",
        "    super(AttentionWithContext, self).build(input_shape)\n",
        "\n",
        "def compute_mask(self, input, input_mask=None):\n",
        "    return None\n",
        "\n",
        "def call(self, x, mask=None):\n",
        "    uit = dot_product(x, self.W)\n",
        "\n",
        "    if self.bias:\n",
        "        uit += self.b\n",
        "\n",
        "    uit = K.tanh(uit)\n",
        "    ait = dot_product(uit, self.u)\n",
        "\n",
        "    a = K.exp(ait)\n",
        "\n",
        "    if mask is not None:\n",
        "        a *= K.cast(mask, K.floatx())\n",
        "\n",
        "    a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "    a = K.expand_dims(a)\n",
        "    weighted_input = x * a\n",
        "    return K.sum(weighted_input, axis=1)\n",
        "\n",
        "def compute_output_shape(self, input_shape):\n",
        "    return input_shape[0], input_shape[-1]"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw3UnZVz0C53"
      },
      "source": [
        "def create_lstm_model(hidden_dim=128):\n",
        "    embedding_dimension=100\n",
        "\n",
        "    #create encoder embedding layer\n",
        "    encoder_inputs = Input(shape=(MAX_LEN_ENC, ),dtype=\"int32\")\n",
        "    encoder_embedding = Embedding(input_dim = num_encoder_tokens,\n",
        "                                output_dim = embedding_dimension,\n",
        "                                input_length = MAX_LEN_ENC,\n",
        "                                weights = [embedding_matrix_encoder],\n",
        "                              trainable = False)(encoder_inputs)\n",
        "    #create encoder lstm layer\n",
        "    encoder_LSTM = LSTM(hidden_dim, return_state=True)\n",
        "    encoder_outputs, state_h, state_c = encoder_LSTM(encoder_embedding)\n",
        "\n",
        "    #create decoder embedding layer\n",
        "    decoder_inputs = Input(shape=(MAX_LEN_DEC, ),dtype=\"int32\")\n",
        "    decoder_embedding = Embedding(input_dim = DECODING_DEPTH,\n",
        "                                output_dim = embedding_dimension,\n",
        "                                input_length = MAX_LEN_DEC,\n",
        "                                weights = [embedding_matrix_decoder],\n",
        "                              trainable = False)(decoder_inputs)\n",
        "    #create decoder LSTM layer using the encoder states\n",
        "    decoder_LSTM = LSTM(hidden_dim, return_state=True, return_sequences=True)(decoder_embedding, initial_state=[state_h, state_c])\n",
        "\n",
        "    if ATTENTION_LAYER:\n",
        "      decoder_outputs = AttentionWithContext(MAX_LEN_DEC)(decoder_LSTM[0])\n",
        "    else:\n",
        "      decoder_outputs, _, _ = decoder_LSTM\n",
        "\n",
        "    #output time distributed dense layer with softmax activation\n",
        "    outputs = TimeDistributed(Dense(DECODING_DEPTH, activation='softmax'))(decoder_outputs)\n",
        "    model = Model([encoder_inputs, decoder_inputs], outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_bilstm_model(hidden_dim=128):\n",
        "    embedding_dimension=100\n",
        "\n",
        "    #create encoder embedding layer\n",
        "    encoder_inputs = Input(shape=(MAX_LEN_ENC, ),dtype=\"int32\")\n",
        "    encoder_embedding = Embedding(input_dim = num_encoder_tokens,\n",
        "                                output_dim = embedding_dimension,\n",
        "                                input_length = MAX_LEN_ENC,\n",
        "                                weights = [embedding_matrix_encoder],\n",
        "                              trainable = False)(encoder_inputs)\n",
        "    \n",
        "    encoder_LSTM = Bidirectional(LSTM(hidden_dim, return_state=True), merge_mode=\"concat\")\n",
        "\n",
        "    encoder_outputs, forward_h, forward_c, backward_c, backward_h = encoder_LSTM(encoder_embedding)\n",
        "    state_h = Concatenate()([forward_h, backward_h])\n",
        "    state_c = Concatenate()([forward_c, backward_c])\n",
        "    encoder_states = [forward_h, forward_c, backward_h, backward_c]\n",
        "    #create encoder lstm layer\n",
        "    #encoder_LSTM = LSTM(hidden_dim, return_state=True)\n",
        "    #encoder_outputs, state_h, state_c = encoder_LSTM(encoder_embedding)\n",
        "\n",
        "    #create decoder embedding layer\n",
        "    decoder_inputs = Input(shape=(MAX_LEN_DEC, ),dtype=\"int32\")\n",
        "    decoder_embedding = Embedding(input_dim = DECODING_DEPTH,\n",
        "                                output_dim = embedding_dimension,\n",
        "                                input_length = MAX_LEN_DEC,\n",
        "                                weights = [embedding_matrix_decoder],\n",
        "                              trainable = False)(decoder_inputs)\n",
        "\n",
        "    decoder_LSTM = LSTM(hidden_dim*2, return_state=True, return_sequences=True)(decoder_embedding, initial_state=[state_h, state_c])\n",
        "    print(decoder_LSTM[0])    \n",
        "\n",
        "    if ATTENTION_LAYER:\n",
        "      decoder_outputs = AttentionWithContext(MAX_LEN_DEC)(decoder_LSTM[0])\n",
        "    else:\n",
        "      decoder_outputs, _, _ = decoder_LSTM\n",
        "\n",
        "    #output time distributed dense layer with softmax activation\n",
        "    outputs = TimeDistributed(Dense(DECODING_DEPTH, activation='softmax'))(decoder_outputs)\n",
        "    model = Model([encoder_inputs, decoder_inputs], outputs)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXrVbdtY8KlO"
      },
      "source": [
        "num_encoder_tokens = len(tokenizer_user.word_index)+1\n",
        "num_decoder_tokens = len(lispress_tokenizer.word_index)+1"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E49hVcwCZlX3"
      },
      "source": [
        "if MODEL_TYPE == MODEL_LSTM:\n",
        "    model = create_lstm_model(HIDDEN_DIM)\n",
        "elif MODEL_TYPE == MODEL_BILSTM:\n",
        "    model = create_bilstm_model(HIDDEN_DIM)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBhqH9uWZlX3",
        "outputId": "a5883d46-c2c8-41a6-aa4c-ee2cd5c4ee43"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 104)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 99)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 104, 100)     1629700     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 99, 100)      1260700     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 8), (None, 8 3488        embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 99, 8), (Non 3488        embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 99, 12607)    113463      lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 3,010,839\n",
            "Trainable params: 120,439\n",
            "Non-trainable params: 2,890,400\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VNJxodZGEUT"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "import tensorflow as tf"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "kitU_G7E8V9U",
        "outputId": "70940858-4815-47f8-81d0-f1e917cd45ca"
      },
      "source": [
        "plot_model(model,show_layer_names=True)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgZ3B2gxZlX3"
      },
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENR1rDjMZlX3"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HAbKEYrZlX3"
      },
      "source": [
        "# data generator for the training\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, input, batch_size=32, num_classes=None, shuffle=False):\n",
        "        self.batch_size = batch_size\n",
        "        self.input = input\n",
        "        self.indices = list(range(len(input[0])))\n",
        "        self.num_classes = num_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch = [self.indices[k] for k in index]\n",
        "        \n",
        "        X, y = self.__get_data(batch)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.index = np.arange(len(self.indices))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.index)\n",
        "\n",
        "    def __get_data(self, batch):\n",
        "        #print(batch[0],batch[-1])\n",
        "        encoder = np.array(self.input[0][batch[0]:batch[-1]+1])\n",
        "        decoder = np.array(self.input[1][batch[0]:batch[-1]+1])\n",
        "        X = [encoder,decoder]\n",
        "        #print(X)\n",
        "        y = decoder_output_creater(self.input[2][batch[0]:batch[-1]+1],len(batch),MAX_LEN_DEC,DECODING_DEPTH)\n",
        "\n",
        "        return X, y\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUtRzMUFOtsR",
        "outputId": "f24dbbc7-3364-4cd1-b352-470cc5e7829a"
      },
      "source": [
        "len(encoder_train)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "129436"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CiSGfkgZlX3",
        "outputId": "7d640e93-72e5-4609-cc44-7439bb7fdc91"
      },
      "source": [
        "batch_size = BATCH_SIZE\n",
        "\n",
        "model.fit(DataGenerator([encoder_train,decoder_train_input,decoder_train],batch_size=batch_size),\n",
        "         batch_size=batch_size,epochs=EPOCHS,validation_data=DataGenerator([encoder_valid,decoder_valid_input,decoder_valid],batch_size=batch_size))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "4044/4044 [==============================] - 589s 146ms/step - loss: 1.8540 - accuracy: 0.6983 - val_loss: 0.8760 - val_accuracy: 0.8131\n",
            "Epoch 2/3\n",
            "4044/4044 [==============================] - 592s 146ms/step - loss: 0.7236 - accuracy: 0.8341 - val_loss: 0.6147 - val_accuracy: 0.8506\n",
            "Epoch 3/3\n",
            "4044/4044 [==============================] - 592s 146ms/step - loss: 0.5827 - accuracy: 0.8525 - val_loss: 0.5434 - val_accuracy: 0.8603\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5f702ada20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3DXt8_6UWJn"
      },
      "source": [
        "#if PERSIST_MODEL_AS is not None:\n",
        "#    model.save(os.path.join(\"models\",PERSIST_MODEL_AS))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tUwHc62ZlX3"
      },
      "source": [
        "def extract_lispress_from_pred(pred,tokenizer):\n",
        "    \"\"\"\n",
        "    Returns the lispress program and lispress token codes from the prediction\n",
        "    \"\"\"\n",
        "    lines = []\n",
        "    codes = []\n",
        "    for p in pred:\n",
        "        line = [tokenizer.index_word[np.argmax(vec)] if np.argmax(vec) > 0 else \"UNKNOWN\" for vec in p ]\n",
        "        code = [np.argmax(vec) for vec in p ]\n",
        "        #print(codes)\n",
        "        lines.append(line)\n",
        "        codes.append(code)\n",
        "    return lines,codes"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qiGVY7VZlX3"
      },
      "source": [
        "def make_prediction(sent,program,user_tokenizer,lispress_tokenizer,model,isText=True):\n",
        "    \"\"\"\n",
        "    Makes prediction for a given sentence\n",
        "    \n",
        "    Method: the input of the encoder will be the given sentence in each turn; the decoder input will be first a <bos> token,\n",
        "    we apply padding to shift the <bos> token to the end of the decoder input. Then we make a prediction, and concat the last token of the\n",
        "    prediction to the previous decoder input. We repeat this until we gets an <eos> token or we reach the max length\n",
        "    \n",
        "    Parameters:\n",
        "    sent (string|list): input code sequence or input text\n",
        "    program: not used\n",
        "    user_tokenizer\n",
        "    lispress_tokenizer\n",
        "    model\n",
        "    isText (boolean): True if the input is text False else\n",
        "    \n",
        "    Returns the predicted lispress program (token codes)\n",
        "    \"\"\"\n",
        "    if isText:\n",
        "        seq = user_tokenizer.texts_to_sequences([sent])[0]\n",
        "    else:\n",
        "        seq = sent\n",
        "    print(\"Question:\", [user_tokenizer.index_word[code] if code in user_tokenizer.index_word else \"unknown\" for code in seq])\n",
        "    decoder = [\"<bos>\"]\n",
        "    length = 0\n",
        "    MAX_LENGTH = 100\n",
        "    decoder_seq = [lispress_tokenizer.word_index[word] for word in decoder]\n",
        "\n",
        "    seq_pad = pad_sequences([seq],maxlen=MAX_LEN,dtype=\"int32\",padding='post', truncating='post')[0]\n",
        "    decoder_pad = pad_sequences([decoder_seq],maxlen=MAX_LEN_DEC,dtype=\"int32\",padding='pre', truncating='pre')[0]\n",
        "\n",
        "    line = [[\"asd\"]]\n",
        "\n",
        "    while length < MAX_LENGTH and line[0][-1] != '<eos>':\n",
        "        pred = model.predict([np.array([seq_pad]),np.array([decoder_pad])])[0]\n",
        "        line,code = extract_lispress_from_pred([pred],lispress_tokenizer)\n",
        "        decoder_seq.append(code[0][-1])\n",
        "        decoder_pad = pad_sequences([decoder_seq],maxlen=MAX_LEN_DEC,dtype=\"int32\",padding='pre', truncating='pre')[0]\n",
        "        length += 1\n",
        "\n",
        "    print(\"Program:\",[lispress_tokenizer.index_word[code0] if code0>0 else \"UNKNOWN\" for code0 in decoder_seq])  \n",
        "\n",
        "    return decoder_seq"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joEMucswPbig"
      },
      "source": [
        "def make_prediction2(sent,program,user_tokenizer,lispress_tokenizer,model,isText=True):\n",
        "    \"\"\"\n",
        "    Makes prediction for a given sentence\n",
        "    \n",
        "    Method: the input of the encoder will be the given sentence in each turn; the decoder input will be first a <bos> token,\n",
        "    we apply padding to shift the <bos> token to the end of the decoder input. Then we make a prediction, and concat the last token of the\n",
        "    prediction to the previous decoder input. We repeat this until we gets an <eos> token or we reach the max length\n",
        "    \n",
        "    Parameters:\n",
        "    sent (string|list): input code sequence or input text\n",
        "    program: not used\n",
        "    user_tokenizer\n",
        "    lispress_tokenizer\n",
        "    model\n",
        "    isText (boolean): True if the input is text False else\n",
        "    \n",
        "    Returns the predicted lispress program (token codes)\n",
        "    \"\"\"\n",
        "    if isText:\n",
        "        seq = user_tokenizer.texts_to_sequences([sent])[0]\n",
        "    else:\n",
        "        seq = sent\n",
        "    print(\"Question:\", [user_tokenizer.index_word[code] if code in user_tokenizer.index_word else \"unknown\" for code in seq])\n",
        "    decoder = [\"<bos>\",\"(\",\"yield\",\":output\"]\n",
        "    length = 4\n",
        "    MAX_LENGTH = MAX_LEN_DEC\n",
        "    decoder_seq = [lispress_tokenizer.word_index[word] for word in decoder]\n",
        "    next_index = 3\n",
        "    seq_pad = pad_sequences([seq],maxlen=MAX_LEN,dtype=\"int32\",padding='post', truncating='post')[0]\n",
        "    decoder_pad = pad_sequences([decoder_seq],maxlen=MAX_LEN_DEC,dtype=\"int32\",padding='post', truncating='post')[0]\n",
        "\n",
        "    line = [[\"asd\",\"asd\",\"asd\",\"asd\"]]\n",
        "    last_token=\"asd\"\n",
        "    while length < MAX_LENGTH and last_token != '<eos>':\n",
        "        #print(next_index)\n",
        "        #print(length)\n",
        "        pred = model.predict([np.array([seq_pad]),np.array([decoder_pad])])[0]\n",
        "        line,code = extract_lispress_from_pred([pred],lispress_tokenizer)\n",
        "        #print(line[0])\n",
        "        decoder_seq.append(code[0][next_index])\n",
        "        last_token = line[0][next_index]\n",
        "        #decoder_seq.append(code[0][-1])\n",
        "        #print(decoder_seq)\n",
        "        if code[0][next_index] == 0:\n",
        "            break\n",
        "        next_index+=1\n",
        "        \n",
        "        decoder_pad = pad_sequences([decoder_seq],maxlen=MAX_LEN_DEC,dtype=\"int32\",padding='post', truncating='post')[0]\n",
        "        length += 1\n",
        "        #print(\" \".join([lispress_tokenizer.index_word[code] for code in decoder_seq]))\n",
        "\n",
        "    print(\"Program:\",[lispress_tokenizer.index_word[code0] if code0>0 else \"UNKNOWN\" for code0 in decoder_seq])  \n",
        "\n",
        "    return decoder_seq"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NU2DWuVw1v9"
      },
      "source": [
        "import math"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBb7OhHmnbF2"
      },
      "source": [
        "def make_prediction3(sents,program,user_tokenizer,lispress_tokenizer,model,isText=True):\n",
        "    \"\"\"\n",
        "    Makes prediction for a given sentence\n",
        "    \n",
        "    Method: the input of the encoder will be the given sentence in each turn; the decoder input will be first a <bos> token,\n",
        "    we apply padding to shift the <bos> token to the end of the decoder input. Then we make a prediction, and concat the last token of the\n",
        "    prediction to the previous decoder input. We repeat this until we gets an <eos> token or we reach the max length\n",
        "    \n",
        "    Parameters:\n",
        "    sent (string|list): input code sequence or input text\n",
        "    program: not used\n",
        "    user_tokenizer\n",
        "    lispress_tokenizer\n",
        "    model\n",
        "    isText (boolean): True if the input is text False else\n",
        "    \n",
        "    Returns the predicted lispress program (token codes)\n",
        "    \"\"\"\n",
        "    if isText:\n",
        "        seqs = user_tokenizer.texts_to_sequences(sents)\n",
        "    else:\n",
        "        seqs = sents\n",
        "    #print(\"Question:\", [user_tokenizer.index_word[code] if code in user_tokenizer.index_word else \"unknown\" for code in seq])\n",
        "    decoder = [\"<bos>\",\"(\"]\n",
        "    length = 2\n",
        "    MAX_LENGTH = MAX_LEN_DEC\n",
        "    decoder_seqs = [[lispress_tokenizer.word_index[word] for word in decoder] for x in seqs]\n",
        "    next_index = 1\n",
        "    seq_pads = pad_sequences(seqs,maxlen=MAX_LEN,dtype=\"int32\",padding='post', truncating='post')\n",
        "    decoder_pads = pad_sequences(decoder_seqs,maxlen=MAX_LEN_DEC,dtype=\"int32\",padding='post', truncating='post')\n",
        "\n",
        "    batch_size=30\n",
        "    while length <= MAX_LENGTH:\n",
        "        #print(next_index)\n",
        "        #print(length)\n",
        "        print(\"next index\",next_index)\n",
        "        for batch in range(0,math.ceil(len(seq_pads)/batch_size)):\n",
        "          start = batch*batch_size\n",
        "          end = (batch+1)*batch_size\n",
        "          #print(start,end)\n",
        "          preds = model.predict([np.array(seq_pads[start:end]),np.array(decoder_pads[start:end])])\n",
        "          #print(preds[:2])\n",
        "          lines,codes = extract_lispress_from_pred(preds,lispress_tokenizer)\n",
        "          #print(line[0])\n",
        "          for idx,seq in enumerate(decoder_seqs[start:end]):\n",
        "            seq.append(codes[idx][next_index])\n",
        "        #last_token = line[0][next_index]\n",
        "        #decoder_seq.append(code[0][-1])\n",
        "        #print(decoder_seq)\n",
        "        #if code[0][next_index] == 0:\n",
        "        #    break\n",
        "        next_index+=1\n",
        "        \n",
        "        decoder_pads = pad_sequences(decoder_seqs,maxlen=MAX_LEN_DEC,dtype=\"int32\",padding='post', truncating='post')\n",
        "        length += 1\n",
        "        #print(\" \".join([lispress_tokenizer.index_word[code] for code in decoder_seq]))\n",
        "\n",
        "    #print(\"Program:\",[lispress_tokenizer.index_word[code0] if code0>0 else \"UNKNOWN\" for code0 in decoder_seq])  \n",
        "    return decoder_seqs"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK8G4EV8ZlX3"
      },
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztmCkTEKZlX3"
      },
      "source": [
        "# load a model trained on the first 1 million data (if you want to skip the training part)\n",
        "#model = load_model('models/model20201121_newtokenizer_50-50-1M.h5')\n",
        "#model.save(root_path+\"/model20201208_parameterized_length100_e6_b32_bilstm_attention.h5\")"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4G0j1STZlX3"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HuBcWiNpECW",
        "outputId": "abfb227e-c4ec-4842-9f23-7fefa83c0c56"
      },
      "source": [
        "preds = make_prediction3(test_data[:],[],user_tokenizer=user_tokenizer_params,lispress_tokenizer=lispress_tokenizer_params,model=model,isText=False)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "next index 1\n",
            "next index 2\n",
            "next index 3\n",
            "next index 4\n",
            "next index 5\n",
            "next index 6\n",
            "next index 7\n",
            "next index 8\n",
            "next index 9\n",
            "next index 10\n",
            "next index 11\n",
            "next index 12\n",
            "next index 13\n",
            "next index 14\n",
            "next index 15\n",
            "next index 16\n",
            "next index 17\n",
            "next index 18\n",
            "next index 19\n",
            "next index 20\n",
            "next index 21\n",
            "next index 22\n",
            "next index 23\n",
            "next index 24\n",
            "next index 25\n",
            "next index 26\n",
            "next index 27\n",
            "next index 28\n",
            "next index 29\n",
            "next index 30\n",
            "next index 31\n",
            "next index 32\n",
            "next index 33\n",
            "next index 34\n",
            "next index 35\n",
            "next index 36\n",
            "next index 37\n",
            "next index 38\n",
            "next index 39\n",
            "next index 40\n",
            "next index 41\n",
            "next index 42\n",
            "next index 43\n",
            "next index 44\n",
            "next index 45\n",
            "next index 46\n",
            "next index 47\n",
            "next index 48\n",
            "next index 49\n",
            "next index 50\n",
            "next index 51\n",
            "next index 52\n",
            "next index 53\n",
            "next index 54\n",
            "next index 55\n",
            "next index 56\n",
            "next index 57\n",
            "next index 58\n",
            "next index 59\n",
            "next index 60\n",
            "next index 61\n",
            "next index 62\n",
            "next index 63\n",
            "next index 64\n",
            "next index 65\n",
            "next index 66\n",
            "next index 67\n",
            "next index 68\n",
            "next index 69\n",
            "next index 70\n",
            "next index 71\n",
            "next index 72\n",
            "next index 73\n",
            "next index 74\n",
            "next index 75\n",
            "next index 76\n",
            "next index 77\n",
            "next index 78\n",
            "next index 79\n",
            "next index 80\n",
            "next index 81\n",
            "next index 82\n",
            "next index 83\n",
            "next index 84\n",
            "next index 85\n",
            "next index 86\n",
            "next index 87\n",
            "next index 88\n",
            "next index 89\n",
            "next index 90\n",
            "next index 91\n",
            "next index 92\n",
            "next index 93\n",
            "next index 94\n",
            "next index 95\n",
            "next index 96\n",
            "next index 97\n",
            "next index 98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAGCB1qqrYM3"
      },
      "source": [
        "ALL=0\n",
        "TP=0\n",
        "for i,pred_ in enumerate(preds):\n",
        "  #print(pred_.index(lispress_tokenizer_params.word_index[\"<eos>\"]))\n",
        "  pred0 = pred_[:pred_.index(lispress_tokenizer_params.word_index[\"<eos>\"])+1 if lispress_tokenizer_params.word_index[\"<eos>\"] in pred_ else -1]\n",
        "  ALL+=1\n",
        "  if len(pred0) == len(test_data_y[i]) and np.sum([ 0 if pred == expected else 1 for pred,expected in zip(pred0,test_data_y[i])] ) == 0:\n",
        "    TP+=1"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_pHxOxbOcBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f2e5ee9-da80-4c9a-c91a-b52418942fd0"
      },
      "source": [
        "print(\"Accuracy:\",TP/ALL)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDakri-V336x",
        "outputId": "aee4b3b5-e77c-44bc-d9af-429075a22d5b"
      },
      "source": [
        "first_error = []\n",
        "for i,pred in enumerate(preds[:]):\n",
        "  max_len = min(len(pred),len(test_data_y[i]))\n",
        "  error_indexes = [ j for j,(pred_,expected) in enumerate(zip(pred[:max_len],test_data_y[i][:max_len])) if pred_ != expected]\n",
        "  if len(error_indexes) > 0:\n",
        "    first_error.append(error_indexes[0])\n",
        "print(len(first_error))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "id": "tN4IhKCUYHVp",
        "outputId": "4ab692ff-7f47-4037-da8b-020f0ecaf584"
      },
      "source": [
        "plt.hist([e for e in first_error if e < 20],bins=range(0,20))\n",
        "plt.xticks(range(0,20),range(0,20))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<matplotlib.axis.XTick at 0x7f5e75176b00>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e74fc6860>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e7518d978>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e74ee6e10>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e74ee65c0>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e74d41a58>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e74d41470>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e74d41128>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e74fa59e8>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e74cd5588>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e74cd5630>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e7505ccc0>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e7505c0b8>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e74d58320>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e74d58b70>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e74d58ac8>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e74ce0278>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e74d58940>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e7505ce80>,\n",
              "  <matplotlib.axis.XTick at 0x7f5e74cd5f98>],\n",
              " [Text(0, 0, '0'),\n",
              "  Text(0, 0, '1'),\n",
              "  Text(0, 0, '2'),\n",
              "  Text(0, 0, '3'),\n",
              "  Text(0, 0, '4'),\n",
              "  Text(0, 0, '5'),\n",
              "  Text(0, 0, '6'),\n",
              "  Text(0, 0, '7'),\n",
              "  Text(0, 0, '8'),\n",
              "  Text(0, 0, '9'),\n",
              "  Text(0, 0, '10'),\n",
              "  Text(0, 0, '11'),\n",
              "  Text(0, 0, '12'),\n",
              "  Text(0, 0, '13'),\n",
              "  Text(0, 0, '14'),\n",
              "  Text(0, 0, '15'),\n",
              "  Text(0, 0, '16'),\n",
              "  Text(0, 0, '17'),\n",
              "  Text(0, 0, '18'),\n",
              "  Text(0, 0, '19')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RpulLVfaD_A",
        "outputId": "365fb30b-af58-4d75-e128-c22f49deb987"
      },
      "source": [
        "print(set([lispress_tokenizer_params.index_word[x[2]] for x in test_data_y]))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'fencescope', 'fenceother', 'execute', 'do', 'fenceattendee', 'let', 'fencemultiaction', 'fencespecify', 'fenceaggregation', 'userpauseresponse', 'fencerecurring', 'fencegibberish', 'pleasantrycalendar', 'pleasantryanythingelsecombined', 'genericpleasantry', 'fenceconferenceroom', 'fencereminder', 'donotconfirm', 'yield', 'fencepeopleqa', 'fencedatetime', 'fenceweather'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3OwcZeQd4to",
        "outputId": "ce78043e-74ae-410c-8e7f-85c936054dfc"
      },
      "source": [
        "print(set([lispress_tokenizer_params.index_word[x[5]] for x in test_data_y if len(x)>5]))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'weatherqueryapi', 'israiny', ':organizer', 'reviseconstraint', ':duration', ':officelocation', 'willsnow', 'findeventwrapperwithdefaults', 'joineventcommand', 'findlastevent', '>', 'personfromrecipient', 'incelsius', '(', 'createcommiteventwrapper', 'execute', ':emailaddress', '==', 'placehasfeature', 'attendeeswithnotresponse', 'iswindy', '<', 'singleton', 'isfree', 'weatheraggregate', ':output', ':location', ':start', ':rating', 'updatecommiteventwrapper', 'size', 'now', 'deletecommiteventwrapper', ':price', 'eventattendance', 'findnumnextevent', 'findmanager', 'today', 'placedescribablelocation', '#', 'attendeeswithresponse', ':phonenumber', ':constraint', 'currentuser', ':end', 'willrain'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-cRufMjgMvL"
      },
      "source": [
        ""
      ],
      "execution_count": 79,
      "outputs": []
    }
  ]
}